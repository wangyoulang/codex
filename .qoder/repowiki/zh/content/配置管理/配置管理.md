# 配置管理

<cite>
**本文档中引用的文件**   
- [config.md](file://docs/config.md)
- [example-config.md](file://docs/example-config.md)
- [config.toml](file://codex-rs/core/src/config/mod.rs)
- [types.rs](file://codex-rs/core/src/config/types.rs)
</cite>

## 目录
1. [简介](#简介)
2. [配置文件结构](#配置文件结构)
3. [核心配置项](#核心配置项)
4. [配置层次结构](#配置层次结构)
5. [完整配置示例](#完整配置示例)
6. [配置验证](#配置验证)

## 简介
Codex 配置系统为用户提供了对模型、执行环境和集成的精细控制。通过配置文件 `~/.codex/config.toml`，用户可以自定义 Codex 的行为，包括模型选择、沙箱设置、MCP 集成和认证方式。配置值可以通过多种机制设置，包括命令行标志、通用 `-c`/`--config` 标志和配置文件。

**Section sources**
- [config.md](file://docs/config.md#L1-L20)

## 配置文件结构
Codex 配置文件 `~/.codex/config.toml` 使用 TOML 格式，支持多种配置项和嵌套表。配置文件的根键必须在表之前列出。配置文件可以包含多个部分，如 `[model]`、`[auth]`、`[ui]` 和 `[sandbox]`，每个部分都有特定的配置项。

**Section sources**
- [config.md](file://docs/config.md#L16-L29)

## 核心配置项
### 模型选择
#### model
指定 Codex 使用的模型。默认值为 `"gpt-5.1-codex-max"`。

```toml
model = "gpt-5.1"
```

#### model_providers
允许用户添加或覆盖内置的模型提供者。每个提供者通过一个唯一的键来标识。

```toml
[model_providers.ollama]
name = "Ollama"
base_url = "http://localhost:11434/v1"
```

#### model_provider
指定从 `model_providers` 映射中使用的提供者。默认值为 `"openai"`。

```toml
model_provider = "ollama"
```

### 认证
#### cli_auth_credentials_store
指定 CLI 认证凭据的存储方式。可选值为 `"file"`、`"keyring"` 或 `"auto"`。

```toml
cli_auth_credentials_store = "file"
```

#### mcp_oauth_credentials_store
指定 MCP OAuth 凭据的存储方式。可选值为 `"auto"`、`"file"` 或 `"keyring"`。

```toml
mcp_oauth_credentials_store = "auto"
```

### 用户界面
#### tui
包含与 TUI 相关的设置，如通知、动画和工具提示。

```toml
[tui]
notifications = true
animations = true
show_tooltips = true
```

### 沙箱
#### sandbox_mode
指定沙箱模式。可选值为 `"read-only"`、`"workspace-write"` 或 `"danger-full-access"`。

```toml
sandbox_mode = "read-only"
```

#### sandbox_workspace_write
当 `sandbox_mode` 为 `"workspace-write"` 时，此表包含额外的沙箱配置。

```toml
[sandbox_workspace_write]
writable_roots = ["/Users/YOU/.pyenv/shims"]
network_access = false
```

**Section sources**
- [config.md](file://docs/config.md#L58-L349)
- [example-config.md](file://docs/example-config.md#L71-L98)

## 配置层次结构
Codex 配置值的优先级顺序如下：
1. 命令行标志（最高优先级）
2. 通用 `-c`/`--config` 标志
3. 配置文件 `~/.codex/config.toml`

环境变量可以覆盖命令行标志，而命令行标志可以覆盖配置文件中的值。这种层次结构允许用户在不同级别上灵活地管理配置。

**Section sources**
- [config.md](file://docs/config.md#L16-L29)

## 完整配置示例
以下是一个完整的 `config.toml` 示例，包含所有主要配置项的注释：

```toml
# Codex 示例配置 (config.toml)
#
# 此文件列出了 Codex 从 config.toml 读取的所有键、它们的默认值和简明解释。
# 这里的值反映了 CLI 中编译的默认值。根据需要进行调整。
#
# 注意
# - 根键必须在 TOML 中位于表之前。
# - 默认为“未设置”的可选键在注释中显示并附有说明。
# - MCP 服务器、配置文件和模型提供者是示例；请删除或编辑。

################################################################################
# 核心模型选择
################################################################################

# Codex 使用的主要模型。默认值：所有平台上的 "gpt-5.1-codex-max"。
model = "gpt-5.1-codex-max"

# /review 功能使用的模型（代码审查）。默认值： "gpt-5.1-codex-max"。
review_model = "gpt-5.1-codex-max"

# 从 [model_providers] 中选择的提供者 ID。默认值： "openai"。
model_provider = "openai"

# 可选的手动模型元数据。未设置时，Codex 会从模型中自动检测。
# 取消注释以强制设置值。
# model_context_window = 128000       # 令牌数；默认值：模型的自动值
# model_auto_compact_token_limit = 0  # 禁用/覆盖自动值；默认值：模型系列特定值
# tool_output_token_limit = 10000  # 每个工具输出存储的令牌数；默认值：gpt-5.1-codex-max 为 10000

################################################################################
# 推理与详细程度（支持 Responses API 的模型）
################################################################################

# 推理努力程度：minimal | low | medium | high | xhigh （默认值：medium；gpt-5.1-codex-max 和 gpt-5.2 上为 xhigh）
model_reasoning_effort = "medium"

# 推理摘要：auto | concise | detailed | none （默认值：auto）
model_reasoning_summary = "auto"

# GPT-5 系列模型的文本详细程度（Responses API）：low | medium | high （默认值：medium）
model_verbosity = "medium"

# 强制为当前模型启用推理摘要（默认值：false）
model_supports_reasoning_summaries = false

################################################################################
# 指令覆盖
################################################################################

# 在 AGENTS.md 之前注入的额外用户指令。默认值：未设置。
# developer_instructions = ""

# （忽略）可选的旧版基础指令覆盖（更推荐使用 AGENTS.md）。默认值：未设置。
# instructions = ""

# 历史压缩提示的内联覆盖。默认值：未设置。
# compact_prompt = ""

# 使用文件路径覆盖内置的基础指令。默认值：未设置。
# experimental_instructions_file = "/absolute/or/relative/path/to/instructions.txt"

# 从文件加载压缩提示覆盖。默认值：未设置。
# experimental_compact_prompt_file = "/absolute/or/relative/path/to/compact_prompt.txt"

################################################################################
# 审批与沙箱
################################################################################

# 何时请求命令审批：
# - untrusted：仅已知安全的只读命令自动运行；其他命令提示
# - on-failure：在沙箱中自动运行；失败时提示升级
# - on-request：模型决定何时请求（默认）
# - never：从不提示（有风险）
approval_policy = "on-request"

# 工具调用的文件系统/网络沙箱策略：
# - read-only （默认）
# - workspace-write
# - danger-full-access （无沙箱；极其危险）
sandbox_mode = "read-only"

# 仅在 sandbox_mode = "workspace-write" 时使用的额外设置。
[sandbox_workspace_write]
# 除了工作区之外的额外可写根目录。默认值：[]
writable_roots = []
# 允许沙箱内的出站网络访问。默认值：false
network_access = false
# 从可写根目录中排除 $TMPDIR。默认值：false
exclude_tmpdir_env_var = false
# 从可写根目录中排除 /tmp。默认值：false
exclude_slash_tmp = false

################################################################################
# 为生成的进程配置 Shell 环境策略
################################################################################

[shell_environment_policy]
# inherit：all （默认）| core | none
inherit = "all"
# 跳过对包含 KEY/SECRET/TOKEN 的名称的默认排除（不区分大小写）。默认值：true
ignore_default_excludes = true
# 要删除的不区分大小写的 glob 模式（例如，"AWS_*", "AZURE_*"）。默认值：[]
exclude = []
# 显式键/值覆盖（始终胜过继承的值）。默认值：{}
set = {}
# 白名单；如果非空，仅保留匹配的变量。默认值：[]
include_only = []
# 实验性：通过用户 shell 配置文件运行。默认值：false
experimental_use_profile = false

################################################################################
# 历史记录与文件打开器
################################################################################

[history]
# save-all （默认）| none
persistence = "save-all"
# 历史记录文件的最大字节数；超出时会修剪最旧的条目。示例：5242880
# max_bytes = 0

# 可点击引用的 URI 方案：vscode （默认）| vscode-insiders | windsurf | cursor | none
file_opener = "vscode"

################################################################################
# UI、通知和杂项
################################################################################

[tui]
# TUI 的桌面通知：布尔值或过滤列表。默认值：true
# 示例：false | ["agent-turn-complete", "approval-requested"]
notifications = false

# 启用欢迎/状态/旋转动画。默认值：true
animations = true

# 从输出中抑制内部推理事件。默认值：false
hide_agent_reasoning = false

# 显示原始推理内容（如果可用）。默认值：false
show_raw_agent_reasoning = false

# 禁用 TUI 中的突发粘贴检测。默认值：false
disable_paste_burst = false

# 跟踪 Windows 上的入门确认（仅限 Windows）。默认值：false
windows_wsl_setup_acknowledged = false

# 外部通知程序命令（argv 数组）。未设置时：禁用。
# 示例：notify = ["notify-send", "Codex"]
# notify = [ ]

# 产品内通知（大多由 Codex 自动设置）。
[notice]
# hide_full_access_warning = true
# hide_rate_limit_model_nudge = true

################################################################################
# 认证与登录
################################################################################

# CLI 登录凭据的持久化位置：file （默认）| keyring | auto
cli_auth_credentials_store = "file"

# ChatGPT 认证流程的基 URL（非 OpenAI API）。默认值：
chatgpt_base_url = "https://chatgpt.com/backend-api/"

# 将 ChatGPT 登录限制到特定的工作区 ID。默认值：未设置。
# forced_chatgpt_workspace_id = ""

# 当 Codex 通常会自动选择时强制登录机制。默认值：未设置。
# 允许的值：chatgpt | api
# forced_login_method = "chatgpt"

# MCP OAuth 凭据的首选存储：auto （默认）| file | keyring
mcp_oauth_credentials_store = "auto"

################################################################################
# 项目文档控制
################################################################################

# 嵌入到第一轮指令中的 AGENTS.md 最大字节数。默认值：32768
project_doc_max_bytes = 32768

# 当 AGENTS.md 在目录级别缺失时的有序回退。默认值：[]
project_doc_fallback_filenames = []

################################################################################
# 工具（用于兼容性的旧版切换）
################################################################################

[tools]
# 启用 Web 搜索工具（别名：web_search_request）。默认值：false
web_search = false

# 启用 view_image 工具，以便代理可以附加本地图像。默认值：true
view_image = true

# （接受别名）您也可以写：
# web_search_request = false

################################################################################
# 集中式功能标志（首选）
################################################################################

[features]
# 将此表留空以接受默认值。设置显式布尔值以选择加入/退出。
unified_exec = false
apply_patch_freeform = false
view_image_tool = true
web_search_request = false
enable_experimental_windows_sandbox = false
skills = false

################################################################################
# 实验性切换（旧版；更推荐使用 [features]）
################################################################################

# 通过自由格式编辑路径包含 apply_patch（影响默认工具集）。默认值：false
experimental_use_freeform_apply_patch = false

# 在此表下定义 MCP 服务器。留空以禁用。
[mcp_servers]

# --- 示例：STDIO 传输 ---
# [mcp_servers.docs]
# command = "docs-server"                 # 必需
# args = ["--port", "4000"]               # 可选
# env = { "API_KEY" = "value" }           # 可选的键/值对直接复制
# env_vars = ["ANOTHER_SECRET"]            # 可选：从前一个环境中转发这些
# cwd = "/path/to/server"                 # 可选的工作目录覆盖
# startup_timeout_sec = 10.0               # 可选；默认 10.0 秒
# # startup_timeout_ms = 10000              # startup timeout 的可选别名（毫秒）
# tool_timeout_sec = 60.0                  # 可选；默认 60.0 秒
# enabled_tools = ["search", "summarize"]  # 可选的允许列表
# disabled_tools = ["slow-tool"]           # 可选的拒绝列表（在允许列表之后应用）

# --- 示例：可流式 HTTP 传输 ---
# [mcp_servers.github]
# url = "https://github-mcp.example.com/mcp"  # 必需
# bearer_token_env_var = "GITHUB_TOKEN"        # 可选；Authorization: Bearer <token>
# http_headers = { "X-Example" = "value" }    # 可选的静态头
# env_http_headers = { "X-Auth" = "AUTH_ENV" } # 可选的从环境变量填充的头
# startup_timeout_sec = 10.0                   # 可选
# tool_timeout_sec = 60.0                      # 可选
# enabled_tools = ["list_issues"]             # 可选的允许列表

################################################################################
# 模型提供者（扩展/覆盖内置提供者）
################################################################################

# 内置提供者包括：
# - openai (Responses API；需要登录或通过认证流程的 OPENAI_API_KEY)
# - oss (Chat Completions API；默认为 http://localhost:11434/v1)

[model_providers]

# --- 示例：使用显式 base URL 或头覆盖 OpenAI ---
# [model_providers.openai]
# name = "OpenAI"
# base_url = "https://api.openai.com/v1"         # 未设置时的默认值
# wire_api = "responses"                         # "responses" | "chat" （默认值因情况而异）
# # requires_openai_auth = true                    # 内置 OpenAI 默认为 true
# # request_max_retries = 4                        # 默认 4；最大 100
# # stream_max_retries = 5                         # 默认 5；最大 100
# # stream_idle_timeout_ms = 300000                # 默认 300_000 (5m)
# # experimental_bearer_token = "sk-example"      # 可选的仅用于开发的直接 bearer token
# # http_headers = { "X-Example" = "value" }
# # env_http_headers = { "OpenAI-Organization" = "OPENAI_ORGANIZATION", "OpenAI-Project" = "OPENAI_PROJECT" }

# --- 示例：Azure（根据端点为 Chat/Responses）---
# [model_providers.azure]
# name = "Azure"
# base_url = "https://YOUR_PROJECT_NAME.openai.azure.com/openai"
# wire_api = "responses"                          # 或根据端点为 "chat"
# query_params = { api-version = "2025-04-01-preview" }
# env_key = "AZURE_OPENAI_API_KEY"
# # env_key_instructions = "在环境中设置 AZURE_OPENAI_API_KEY"

# --- 示例：本地 OSS（例如，与 Ollama 兼容）---
# [model_providers.ollama]
# name = "Ollama"
# base_url = "http://localhost:11434/v1"
# wire_api = "chat"

################################################################################
# 配置文件（命名的预设）
################################################################################

# 活动配置文件名称。未设置时，不应用任何配置文件。
# profile = "default"

[profiles]

# [profiles.default]
# model = "gpt-5.1-codex-max"
# model_provider = "openai"
# approval_policy = "on-request"
# sandbox_mode = "read-only"
# model_reasoning_effort = "medium"
# model_reasoning_summary = "auto"
# model_verbosity = "medium"
# chatgpt_base_url = "https://chatgpt.com/backend-api/"
# experimental_compact_prompt_file = "./compact_prompt.txt"
# include_apply_patch_tool = false
# experimental_use_freeform_apply_patch = false
# tools_web_search = false
# tools_view_image = true
# features = { unified_exec = false }

################################################################################
# 项目（信任级别）
################################################################################

# 将特定工作树标记为受信任。仅识别 "trusted"。
[projects]
# [projects."/absolute/path/to/project"]
# trust_level = "trusted"

################################################################################
# OpenTelemetry (OTEL) – 默认禁用
################################################################################

[otel]
# 在日志中包含用户提示文本。默认值：false
log_user_prompt = false
# 应用于遥测的环境标签。默认值： "dev"
environment = "dev"
# 导出器：none （默认）| otlp-http | otlp-grpc
exporter = "none"

# 示例 OTLP/HTTP 导出器配置
# [otel.exporter."otlp-http"]
# endpoint = "https://otel.example.com/v1/logs"
# protocol = "binary"                         # "binary" | "json"

# [otel.exporter."otlp-http".headers]
# "x-otlp-api-key" = "${OTLP_TOKEN}"

# 示例 OTLP/gRPC 导出器配置
# [otel.exporter."otlp-grpc"]
# endpoint = "https://otel.example.com:4317",
# headers = { "x-otlp-meta" = "abc123" }

# 示例带有相互 TLS 的 OTLP 导出器
# [otel.exporter."otlp-http"]
# endpoint = "https://otel.example.com/v1/logs"
# protocol = "binary"

# [otel.exporter."otlp-http".headers]
# "x-otlp-api-key" = "${OTLP_TOKEN}"

# [otel.exporter."otlp-http".tls]
# ca-certificate = "certs/otel-ca.pem"
# client-certificate = "/etc/codex/certs/client.pem"
# client-private-key = "/etc/codex/certs/client-key.pem"
```

**Section sources**
- [example-config.md](file://docs/example-config.md#L1-L363)

## 配置验证
为了验证配置文件的正确性，用户可以使用 Codex 提供的命令行工具。例如，运行 `codex config validate` 可以检查配置文件的语法和逻辑错误。此外，用户可以通过查看日志文件 `~/.codex/logs` 来调试配置问题。

**Section sources**
- [config.md](file://docs/config.md#L537-L663)